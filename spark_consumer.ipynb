{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ca32bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import praw\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fdb6ba0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"config.json\", \"r\") as jsonfile:\n",
    "    data = json.load(jsonfile)  # Reading the config file\n",
    "#     print(\"Config data read successful\", data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "af84bea6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\marke\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pyspark\\streaming\\context.py:72: FutureWarning: DStream is deprecated as of Spark 3.4.0. Migrate to Structured Streaming.\n",
      "  warnings.warn(\n",
      "C:\\Users\\marke\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pyspark\\sql\\context.py:113: FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from collections import namedtuple  # Each element will be assigned a field\n",
    "import sys\n",
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.streaming import StreamingContext\n",
    "from pyspark.sql import SparkSession,SQLContext\n",
    "# Allow us to order things in decscending order\n",
    "from pyspark.sql.functions import desc\n",
    "\n",
    "# create spark configuration\n",
    "conf = SparkConf()\n",
    "conf.setAppName(\"RedditStreamApp\")\n",
    "# create spark context with the above configuration\n",
    "sc = SparkContext(conf=conf)\n",
    "sc.setLogLevel(\"ERROR\")\n",
    "# create the Streaming Context from the above spark context with interval size 10 seconds\n",
    "ssc = StreamingContext(sc, 10)\n",
    "# setting a checkpoint to allow RDD recovery\n",
    "####ssc.checkpoint(\"checkpoint_RedditApp\")\n",
    "# read data from port 5590\n",
    "# socket_stream = ssc.socketTextStream(\"localhost\", 5590)\n",
    "\n",
    "\n",
    "# sc = SparkContext() # Establish an entry point of Apache Spark functionality.\n",
    "# ssc = StreamingContext(sc, 10) # Create streaming context with intervals of 10 seconds.\n",
    "sqlContext = SQLContext(sc) # Initialising Spark SQL functionalities.\n",
    "\n",
    "socket_stream = ssc.socketTextStream(\"127.0.0.1\", 5590)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "53970e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Modify the code here to match your logic in reddit_producer.py\n",
    "#**********************\n",
    "lines = socket_stream.window(20)\n",
    "fields = (\"author\",'date','time')\n",
    "RedditComment = namedtuple('RedditComment', fields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6fa2424c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sql_context_instance(spark_context):\n",
    "    if ('sqlContextSingletonInstance' not in globals()):\n",
    "        globals()['sqlContextSingletonInstance'] = SQLContext(spark_context)\n",
    "    return globals()['sqlContextSingletonInstance']\n",
    "\n",
    "\n",
    "def test_content(string):\n",
    "    print(string)\n",
    "    return eval(string)\n",
    "    \n",
    "def get_avg_word(df):\n",
    "\n",
    "    return 0\n",
    "\n",
    "def process_rdd(time, rdd):\n",
    "    print(\"----------- %s -----------\" % str(time))\n",
    "    try:\n",
    "        # Get spark sql singleton context from the current context\n",
    "        sql_context = get_sql_context_instance(rdd.context)\n",
    "\n",
    "        \n",
    "        # modify the mapping to account for data dictionary now being passed to it\n",
    "        row_rdd = rdd.map(lambda rec: RedditComment(rec['author'],rec['date'],rec['time']))\n",
    "        comments_df = sql_context.createDataFrame(row_rdd)\n",
    "        comments_df.registerTempTable(\"comments\")\n",
    "        comments_df_sql = sql_context.sql(\n",
    "            \"select * from comments limit 10\")\n",
    "        comments_df_sql.show()\n",
    "\n",
    "        #####\n",
    "        rows = comments_df.collect()\n",
    "        name = rows['author']\n",
    "\n",
    "\n",
    "    except:\n",
    "        e = sys.exc_info()[0]\n",
    "        print(\"Error: %s\" % e)\n",
    "\n",
    "\n",
    "\n",
    "(lines.map(lambda text: test_content(text)).foreachRDD(process_rdd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "433de608",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------- 2023-12-03 17:58:20 -----------\n",
      "Error: <class 'ValueError'>\n",
      "----------- 2023-12-03 17:58:30 -----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\marke\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pyspark\\sql\\dataframe.py:329: FutureWarning: Deprecated in 2.0, use createOrReplaceTempView instead.\n",
      "  warnings.warn(\"Deprecated in 2.0, use createOrReplaceTempView instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------+--------+\n",
      "|              author|      date|    time|\n",
      "+--------------------+----------+--------+\n",
      "|    spookyhellkitten|2023-12-03|17:45:47|\n",
      "|       After_Ad_8841|2023-12-03|17:45:48|\n",
      "|      Lemon_head_guy|2023-12-03|17:45:49|\n",
      "| Spiritual-Wind-3898|2023-12-03|17:45:50|\n",
      "|       ThorneInMyEye|2023-12-03|17:45:54|\n",
      "|CalligrapherShort121|2023-12-03|17:46:04|\n",
      "|        Pitsmithy_89|2023-12-03|17:46:14|\n",
      "|          jmochicago|2023-12-03|17:46:27|\n",
      "|      itsshakespeare|2023-12-03|17:46:27|\n",
      "|  Mantequilla_Stotch|2023-12-03|17:46:29|\n",
      "+--------------------+----------+--------+\n",
      "\n",
      "Error: <class 'TypeError'>\n",
      "----------- 2023-12-03 17:58:40 -----------\n",
      "+--------------------+----------+--------+\n",
      "|              author|      date|    time|\n",
      "+--------------------+----------+--------+\n",
      "|    spookyhellkitten|2023-12-03|17:45:47|\n",
      "|       After_Ad_8841|2023-12-03|17:45:48|\n",
      "|      Lemon_head_guy|2023-12-03|17:45:49|\n",
      "| Spiritual-Wind-3898|2023-12-03|17:45:50|\n",
      "|       ThorneInMyEye|2023-12-03|17:45:54|\n",
      "|CalligrapherShort121|2023-12-03|17:46:04|\n",
      "|        Pitsmithy_89|2023-12-03|17:46:14|\n",
      "|          jmochicago|2023-12-03|17:46:27|\n",
      "|      itsshakespeare|2023-12-03|17:46:27|\n",
      "|  Mantequilla_Stotch|2023-12-03|17:46:29|\n",
      "+--------------------+----------+--------+\n",
      "\n",
      "Error: <class 'TypeError'>\n",
      "----------- 2023-12-03 17:58:50 -----------\n",
      "+-----------------+----------+--------+\n",
      "|           author|      date|    time|\n",
      "+-----------------+----------+--------+\n",
      "|   itsshakespeare|2023-12-03|17:58:19|\n",
      "|SavannahInChicago|2023-12-03|17:58:20|\n",
      "|     Bugsandgrubs|2023-12-03|17:58:23|\n",
      "|         Isgortio|2023-12-03|17:58:30|\n",
      "|   tara_tara_tara|2023-12-03|17:58:35|\n",
      "+-----------------+----------+--------+\n",
      "\n",
      "Error: <class 'TypeError'>\n",
      "----------- 2023-12-03 17:59:00 -----------\n",
      "+--------------+----------+--------+\n",
      "|        author|      date|    time|\n",
      "+--------------+----------+--------+\n",
      "|      Isgortio|2023-12-03|17:58:30|\n",
      "|tara_tara_tara|2023-12-03|17:58:35|\n",
      "+--------------+----------+--------+\n",
      "\n",
      "Error: <class 'TypeError'>\n",
      "----------- 2023-12-03 17:59:10 -----------\n",
      "Error: <class 'ValueError'>\n",
      "----------- 2023-12-03 17:59:20 -----------\n",
      "+--------------------+----------+--------+\n",
      "|              author|      date|    time|\n",
      "+--------------------+----------+--------+\n",
      "|   Dull_Reindeer1223|2023-12-03|17:58:46|\n",
      "|InternetPersonalitea|2023-12-03|17:58:59|\n",
      "|            Mike7676|2023-12-03|17:59:01|\n",
      "+--------------------+----------+--------+\n",
      "\n",
      "Error: <class 'TypeError'>\n",
      "----------- 2023-12-03 17:59:30 -----------\n"
     ]
    }
   ],
   "source": [
    "ssc.start()\n",
    "# ssc.awaitTermination()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "26ff499e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: <class 'py4j.protocol.Py4JJavaError'>\n"
     ]
    }
   ],
   "source": [
    "ssc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b43bba1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
